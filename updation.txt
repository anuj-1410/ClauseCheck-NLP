1Ô∏è‚É£ DOCUMENT PARSER ‚Äî ‚úÖ Good

document_parser

Strength:

Clean PDF detection logic

Smart OCR trigger (<50 chars)

Multi-format support

Improvement:

Add layout-aware PDF parsing (pdfplumber instead of PyPDF2)

Preserve headings & numbering (currently lost)

Extract section numbers explicitly

Why?
Clause segmentation becomes more accurate.

Works for:
‚úî English contracts
‚úî Hindi contracts (Unicode-safe)

2Ô∏è‚É£ LANGUAGE DETECTION ‚Äî ‚ö† Upgrade for Mixed EN + HI
Current Problem

langdetect unstable for mixed text.

üî• Upgrade
Step 1: Script Ratio Detection

Count Devanagari characters:

If:

Devanagari chars > 30%

‚Üí Hindi

This is deterministic.

Step 2: Add fastText Language Model

Use:

lid.176.bin

Better at mixed-language detection.

Final Logic

Script detection

fastText validation

Fallback to langdetect

Improvement

Mixed Hindi-English contracts correctly classified.

3Ô∏è‚É£ ENTITY EXTRACTOR ‚Äî ‚ö† Medium Level

entity_extractor

Good:

Lazy loading

Regex enrichment

Separate Hindi pipeline

Limitations:

Using en_core_web_sm ‚Üí weak legal NER

LAW label in spaCy small model is poor

No custom training

Upgrade Path:

üî• English Upgrade
Use en_core_web_trf (transformer-based)

üî• Hindi Upgrade
There is no strong Legal Hindi NER model.

So build hybrid system:

Layer 1:

Stanza NER

Layer 2:

Regex for:

‡§ß‡§æ‡§∞‡§æ 74

‡§Ö‡§ß‡§ø‡§®‡§ø‡§Ø‡§Æ

‡§Ö‡§®‡•Å‡§ö‡•ç‡§õ‡•á‡§¶

‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§Ö‡§®‡•Å‡§¨‡§Ç‡§ß ‡§Ö‡§ß‡§ø‡§®‡§ø‡§Ø‡§Æ

Layer 3:

Legal Gazetteer Dictionary

Example:

[
"‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§Ö‡§®‡•Å‡§¨‡§Ç‡§ß ‡§Ö‡§ß‡§ø‡§®‡§ø‡§Ø‡§Æ, 1872",
"‡§∏‡•Ç‡§ö‡§®‡§æ ‡§™‡•ç‡§∞‡•å‡§¶‡•ç‡§Ø‡•ã‡§ó‡§ø‡§ï‡•Ä ‡§Ö‡§ß‡§ø‡§®‡§ø‡§Ø‡§Æ, 2000",
"‡§â‡§™‡§≠‡•ã‡§ï‡•ç‡§§‡§æ ‡§∏‡§Ç‡§∞‡§ï‡•ç‡§∑‡§£ ‡§Ö‡§ß‡§ø‡§®‡§ø‡§Ø‡§Æ, 2019"
]

4Ô∏è‚É£ OBLIGATION DETECTOR ‚Äî ‚ö† Surface-Level

obligation_detector

Current approach:

Modal word matching

Regex sentence split

Extract strength

Problem:
You are NOT using dependency parsing.

So:

You cannot reliably detect:

Who is the subject

What exactly is the action

Power imbalance

Upgrade:

Use spaCy dependency tree:

Extract:
nsubj
ROOT verb
dobj

üî• English Upgrade

Use spaCy dependency parsing:

Extract:

nsubj

ROOT

dobj

Build structured obligation object.

üî• Hindi Upgrade

Use Stanza dependency parsing:

Detect:

Subject (nsubj)

Verb

Object

Handle passive forms like:

‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§è‡§ó‡§æ

‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ

‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è

Improvement

You now detect:

Power imbalance

One-sided authority

Mutual vs unilateral obligations

Works in both languages.

5Ô∏è‚É£ RISK DETECTOR ‚Äî ‚ö† Heavily Regex-Based

risk_detector

Strength:

Clean category structure

Severity tagging

Hindi support

Weakness:

Fully pattern-based

No semantic similarity

Cannot detect paraphrased risks

Example it will miss:
"The consultant shall bear responsibility without limitation."

Upgrade Required:

Use multilingual embedding model:

sentence-transformers/paraphrase-multilingual-mpnet-base-v2
How It Works

Define risk prototype in English.

Encode clause (Hindi or English).

Compute similarity.

If similarity > threshold ‚Üí flag.

This works cross-lingually.

Hindi clause:

‚Äú‡§¨‡§ø‡§®‡§æ ‡§∏‡•Ä‡§Æ‡§æ ‡§ï‡•á ‡§¶‡§æ‡§Ø‡§ø‡§§‡•ç‡§µ‚Äù

English prototype:

‚ÄúUnlimited liability without cap.‚Äù

They match semantically.

Result

Risk detection now meaning-based, not word-based.

6Ô∏è‚É£ RESPONSIBILITY & AMBIGUITY DETECTOR ‚Äî ‚≠ê Strong

responsibility_detector

This is actually one of your strongest modules.

You detect:

Passive voice

Vague terms

Missing subjects

That‚Äôs very good.

Upgrade:
Use spaCy dependency to detect passive (nsubjpass) instead of regex.

üî• English Upgrade
Use:
token.dep_ == "nsubjpass"

üî• Hindi Upgrade
Use Stanza:
Detect passive constructions like:

‡§ó‡§Ø‡§æ

‡§ï‡•Ä ‡§ó‡§à

‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§è‡§ó‡§æ

Use dependency labels, not regex only.

7Ô∏è‚É£ COMPLIANCE ENGINE ‚Äî ‚ö† Presence-Based Only

compliance_checker

Current model:
Check if keywords exist ‚Üí mark clause present.

Problem:
Presence ‚â† quality.

Example:
Termination clause exists but:
"No notice required"

Still considered compliant.

Upgrade:

After clause detection:
Validate quality.

Example for termination:

Is notice period defined?

Is termination mutual?

Is duration specified?

Turn compliance into structural validation, not keyword presence.

üî• English Structural Validation

For termination clause:

Notice defined?

Mutual?

Cure period?

Grounds specified?

üî• Hindi Structural Validation

Check for:

‡§∏‡•Ç‡§ö‡§®‡§æ ‡§Ö‡§µ‡§ß‡§ø

‡§ï‡§æ‡§∞‡§£

‡§™‡§æ‡§∞‡§∏‡•ç‡§™‡§∞‡§ø‡§ï ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§∞

‡§Ö‡§µ‡§ß‡§ø

Now compliance = quality-based, not presence-based.

8Ô∏è‚É£ JURISDICTION ENGINE ‚Äî ‚≠ê Very Good

jurisdiction_engine

This is strong architecture.

But currently:
It is static mapping.

Upgrade:
Make risk severity jurisdiction-aware.

Example:
Non-compete in India ‚Üí High risk
Non-compete in US ‚Üí Medium risk (depends state)

Add dynamic severity adjustment.

9Ô∏è‚É£ CONTRACT COMPARATOR ‚Äî ‚ö† Weak Matching Logic

contract_comparator

Current:
SequenceMatcher similarity threshold 0.4

Problem:
This is lexical similarity only.

Two clauses meaning same but paraphrased:
Will show modified.

Upgrade:
Multilingual embeddings.

Now:

Hindi ‚Üî Hindi
English ‚Üî English
Even Hindi ‚Üî English

Semantic diff works.

üîü SUMMARIZER ‚Äî ‚ö† Academic-Level Only

summarizer

You built TF-IDF extractive summary.

Problem:
Legal contracts need:
Section-level summary
Not generic TF-IDF

Upgrade:

use same llm summarization as using now but change the fallback mechanisma to TextRank

1Ô∏è‚É£1Ô∏è‚É£ TIMELINE EXTRACTOR ‚Äî ‚≠ê Good Utility

timeline_extractor

Nice regex coverage.

Upgrade:
Normalize extracted dates to actual datetime objects.
Right now, they are raw strings.

Add Hindi patterns:

Dates:

\d{1,2}\s+(‡§ú‡§®‡§µ‡§∞‡•Ä|‡§´‡§º‡§∞‡§µ‡§∞‡•Ä|‡§Æ‡§æ‡§∞‡•ç‡§ö...)

Deadlines:

‡§ï‡•á ‡§≠‡•Ä‡§§‡§∞

‡§∏‡•á ‡§™‡§π‡§≤‡•á

‡§§‡§ï

Normalize to datetime objects for both language.

This allows:

Timeline sorting

Gantt visualization
